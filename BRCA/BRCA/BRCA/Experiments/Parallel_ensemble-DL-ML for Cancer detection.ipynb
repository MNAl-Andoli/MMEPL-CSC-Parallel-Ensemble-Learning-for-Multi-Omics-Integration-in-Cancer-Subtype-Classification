{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c99e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from os.path import exists\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea16957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 14:31:04,797\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.6</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.10.6', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '10.193.15.164', 'raylet_ip_address': '10.193.15.164', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-07-11_14-31-02_405970_12411/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-07-11_14-31-02_405970_12411/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2023-07-11_14-31-02_405970_12411', 'metrics_export_port': 57908, 'gcs_address': '10.193.15.164:65095', 'address': '10.193.15.164:65095', 'dashboard_agent_listen_port': 52365, 'node_id': '304986290cbcd4f93be993d40d2a0b795968523e81c0d40ee9396dbf'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81bf3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train Data : (511, 100)\n",
      "Shape of Test Data : (511,)\n"
     ]
    }
   ],
   "source": [
    "X = np.loadtxt('data/latent_fpkm_gistic_rppa.csv', delimiter=',')\n",
    "\n",
    "\n",
    "y = np.loadtxt('data/encoded_labels.csv')\n",
    "\n",
    "print(\"Shape of Train Data : {}\".format(X.shape))\n",
    "print(\"Shape of Test Data : {}\".format(y.shape))\n",
    "\n",
    "input_dim=X.shape[1]\n",
    "num_classes=len(np.unique(y))\n",
    "\n",
    "num_epochs=200\n",
    "batch_size=128\n",
    "num_P=2 #num_processors per one function\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "Time_Now= now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "dataset= 'BRCA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2de82ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 14:31:19,999\tINFO worker.py:1352 -- Connecting to existing Ray cluster at address: 10.193.15.164:65095...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m PC\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (cluster):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# parallel in cluster of PCs\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     PC\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/worker.py:1374\u001b[0m, in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m RayContext(\u001b[38;5;28mdict\u001b[39m(_global_node\u001b[38;5;241m.\u001b[39maddress_info, node_id\u001b[38;5;241m=\u001b[39mnode_id\u001b[38;5;241m.\u001b[39mhex()))\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1375\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaybe you called ray.init twice by accident? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1376\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis error can be suppressed by passing in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1377\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_reinit_error=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1378\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mray.shutdown()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m prior to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mray.init()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1379\u001b[0m         )\n\u001b[1;32m   1381\u001b[0m _system_config \u001b[38;5;241m=\u001b[39m _system_config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_system_config, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'."
     ]
    }
   ],
   "source": [
    "cluster= True\n",
    "PC=''\n",
    "if (cluster):\n",
    "    ray.init(address='auto') # parallel in cluster of PCs\n",
    "    PC='Cluster'\n",
    "else:\n",
    "    ray.init() # parallel in one PC\n",
    "    PC='Leovo'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0169818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce results\n",
    "path = 'data/results_fpkm_gistic_rppa/'\n",
    "\n",
    "def write_results(results, path):\n",
    "    \n",
    "    file_exists = exists(path)\n",
    "    if not(file_exists):\n",
    "        with open(path,\"a+\") as f:\n",
    "            f.write(results)\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        with open(path,\"a+\") as f:\n",
    "            f.write(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f840b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 14:31:22.152175: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-11 14:31:23.149367: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-11 14:31:23.149393: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-11 14:31:25.967029: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-11 14:31:25.967567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-11 14:31:25.967588: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.20)\n",
    "\n",
    "input_dim=x_train.shape[1]\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    #early_stop = EarlyStopping(monitor='loss', patience=2)\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    model.add(Dense(128, activation='relu', input_shape=(input_dim,),kernel_initializer='random_uniform'))\n",
    "\n",
    "    model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "    #model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "    #model.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\n",
    "    #model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    #model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452842c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12671)\u001b[0m 2023-07-11 14:31:28.272179: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=12671)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m 2023-07-11 14:31:28.262801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m 2023-07-11 14:31:28.600060: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m 2023-07-11 14:31:28.600108: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[2m\u001b[36m(pid=12671)\u001b[0m 2023-07-11 14:31:28.779840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=12671)\u001b[0m 2023-07-11 14:31:28.779882: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m 2023-07-11 14:31:30.180569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m 2023-07-11 14:31:30.180671: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m 2023-07-11 14:31:30.180688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(pid=12671)\u001b[0m 2023-07-11 14:31:30.457928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=12671)\u001b[0m 2023-07-11 14:31:30.458055: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=12671)\u001b[0m 2023-07-11 14:31:30.458087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(run_model pid=12670)\u001b[0m 2023-07-11 14:31:31.887518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(run_model pid=12670)\u001b[0m 2023-07-11 14:31:31.887593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (alandoli-Lenovo-Z50-70): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(run_model pid=12670)\u001b[0m 2023-07-11 14:31:31.888635: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(run_model pid=12670)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(run_model pid=12671)\u001b[0m 2023-07-11 14:31:31.976450: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(run_model pid=12671)\u001b[0m 2023-07-11 14:31:31.976510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (alandoli-Lenovo-Z50-70): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(run_model pid=12671)\u001b[0m 2023-07-11 14:31:31.976898: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(run_model pid=12671)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run_model pid=12670)\u001b[0m (408, 100)\n",
      "\u001b[2m\u001b[36m(run_model pid=12671)\u001b[0m (408, 100)\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "\u001b[2m\u001b[36m(run_model pid=12670)\u001b[0m (408, 100)\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      " 1/16 [>.............................] - ETA: 0s\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "\u001b[2m\u001b[36m(run_model pid=12671)\u001b[0m (408, 100)\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "\u001b[2m\u001b[36m(run_model pid=12670)\u001b[0m (408, 100)\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "(511, 105) (511, 5)\n",
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "@ray.remote(num_cpus=num_P)\n",
    "def run_model(i, X,x_train , y_train, x_test , y_test):\n",
    "    \n",
    "    t_temp=time.time()\n",
    "    #individual classifier\n",
    "    input_dim=x_train.shape[1]\n",
    "\n",
    "    model1=create_model()\n",
    "    #hist = model1.fit(x_train , y_train , epochs=20)\n",
    "    #hist = model1.fit(x_train , y_train , epochs=20, batch_size=5, verbose=0)\n",
    "    print(x_train.shape)\n",
    "    hist = model1.fit(x_train , y_train , epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "    y_predict=model1.predict(x_test)\n",
    "    y_predict=np.argmax(y_predict,axis=1)\n",
    "\n",
    "    #_, accuracy = model1.evaluate(x_test, y_test)\n",
    "    #Accuracy\n",
    "    acc=accuracy_score(y_test, y_predict)\n",
    "    prc=precision_score(y_test, y_predict, average='weighted')\n",
    "    rec=recall_score(y_test, y_predict, average='weighted')\n",
    "    f1=f1_score(y_test, y_predict, average='weighted')\n",
    "    \n",
    " \n",
    "    results = 'DL:%d' %(i) + ', Acc: %.2f' % (acc*100) + ', Pre: %.2f' % (prc*100)\n",
    "    results += ', Rec: %.2f' % (rec*100) + ', F1: %.2f' % (f1*100) + ', T:%.2f ' % (time.time()-t_temp) + ', PC: ' + PC\n",
    "    results += ', Num Processors: ' + str(num_P) + ', Eb:%d ' %(num_epochs) + ', Bs:%d ' %(batch_size) + ', Date:' + Time_Now + '\\n'\n",
    "    \n",
    "    predictions=model1.predict(X)\n",
    "    max_indices = np.argmax(predictions,axis=1)\n",
    "\n",
    "    return_values=[]\n",
    "    return_values.append(np.array(max_indices))\n",
    "    return_values.append(results)\n",
    "\n",
    "    return return_values\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "Return_values=[]\n",
    "\n",
    "Return_values=[run_model.remote(i, X,x_train , y_train, x_test , y_test) for i in range(5)]\n",
    "\n",
    "#collect the output from classifiers that used original features\n",
    "\n",
    "outputs_original=ray.get(Return_values)\n",
    "\n",
    "all_time_before=time.time()-t1\n",
    "\n",
    "#0 indicates to the the outputs_original\n",
    "#1 indicates to results_original\n",
    "predictions=outputs_original[0][0]\n",
    "for i in range(1,5):\n",
    "    predictions=np.vstack((predictions,outputs_original[i][0]))\n",
    "\n",
    "predictions= np.transpose(predictions)\n",
    "\n",
    "# concat predictions with olriginal features\n",
    "new_X=np.concatenate((X, predictions), axis=1)\n",
    "#new_X=predictions #np.concatenate((X, predictions), axis=1)\n",
    "#====z_score normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(new_X)\n",
    "new_X = scaler.fit_transform(new_X)\n",
    "print(new_X.shape, predictions.shape)\n",
    "\n",
    "new_x_train,new_x_test,y_train,y_test = train_test_split(new_X,y,test_size = 0.10)\n",
    "\n",
    "input_dim=new_x_train.shape[1]\n",
    "\n",
    "\n",
    "#Save the performance results of original classifiers\n",
    "path2= path +\"Res_Singl_Parallel_DL_Original.txt\" # the name of the file\n",
    "results_before='Dataset:' + dataset + '=============================================\\n'\n",
    "\n",
    "for i in range(5):\n",
    "    results_before+=outputs_original[i][1]\n",
    "\n",
    "results_before+= 'Done...in time:' + str(round(all_time_before)) + '\\n'\n",
    "    \n",
    "write_results(results_before, path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c65f8e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_394746/3367525961.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  NN_clf1=KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
      "/tmp/ipykernel_394746/3367525961.py:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  NN_clf2=KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
      "/tmp/ipykernel_394746/3367525961.py:7: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  NN_clf3=KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
      "/tmp/ipykernel_394746/3367525961.py:9: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  NN_clf4=KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
      "/tmp/ipykernel_394746/3367525961.py:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  NN_clf5=KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "input_dim=new_x_train.shape[1]\n",
    "\n",
    "NN_clf1=KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "NN_clf1._estimator_type = \"classifier\"\n",
    "NN_clf2=KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "NN_clf2._estimator_type = \"classifier\"\n",
    "NN_clf3=KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "NN_clf3._estimator_type = \"classifier\"\n",
    "NN_clf4=KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "NN_clf4._estimator_type = \"classifier\"\n",
    "NN_clf5=KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "NN_clf5._estimator_type = \"classifier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7a5b4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN1', <keras.wrappers.scikit_learn.KerasClassifier at 0x7f1cf6d956c0>),\n",
       " ('NN2', <keras.wrappers.scikit_learn.KerasClassifier at 0x7f1cf6d94610>),\n",
       " ('NN3', <keras.wrappers.scikit_learn.KerasClassifier at 0x7f1cf6d945b0>),\n",
       " ('NN4', <keras.wrappers.scikit_learn.KerasClassifier at 0x7f1cf6d94e50>),\n",
       " ('NN5', <keras.wrappers.scikit_learn.KerasClassifier at 0x7f1cf6d951b0>),\n",
       " ('dtc', DecisionTreeClassifier()),\n",
       " ('rfc', RandomForestClassifier()),\n",
       " ('knn', KNeighborsClassifier()),\n",
       " ('xgb',\n",
       "  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                predictor=None, random_state=None, ...))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc =  DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "knn =  KNeighborsClassifier()\n",
    "xgb = xgboost.XGBClassifier()\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "#intermediate = [('NN1', NN_clf1), ('NN2', NN_clf2), ('NN3', NN_clf3), ('NN4', NN_clf4), ('NN5', NN_clf5),('dtc',dtc),('rfc',rfc),('knn',knn) ,('xgb',xgb),('svm',svm)]\n",
    "intermediate = [('NN1', NN_clf1), ('NN2', NN_clf2), ('NN3', NN_clf3),\n",
    "                ('NN4', NN_clf4), ('NN5', NN_clf5),('dtc',dtc),('rfc',rfc),\n",
    "                ('knn',knn) ,('xgb',xgb)]\n",
    "intermediate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc001faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "# run after ad preictions of first level\n",
    "t1=time.time()\n",
    "@ray.remote(num_cpus=num_P)\n",
    "def parallel_ensemble(algo,clf_name, p_X,p_y):\n",
    "    t_temp=time.time()\n",
    "    y_predict = cross_val_predict(algo,p_X,p_y, cv=5) \n",
    "    #score = cross_val_score( algo,new_X,y,cv = 10,scoring = 'accuracy')\n",
    "    #print(\"The accuracy score of {} is:\".format(algo),score.mean(), \"time: \", time.time()-t_temp)\n",
    "    acc=accuracy_score(y_predict,y)\n",
    "    prc=precision_score(y_predict,y, average='weighted')\n",
    "    rec=recall_score(y_predict,y, average='weighted')\n",
    "    f1=f1_score(y_predict,y, average='weighted')\n",
    "\n",
    "\n",
    "    results = 'Model: ' + clf_name + ', Acc: %.2f' % (acc*100) + ', Pre: %.2f' % (prc*100)\n",
    "    results += ', Rec: %.2f' % (rec*100) + ', F1: %.2f' % (f1*100) + ', T:%.2f ' % (time.time()-t_temp) + ', PC: ' + PC\n",
    "    results += ', Num Processors: ' + str(num_P) + ', Eb:%d ' %(num_epochs) + ', Bs:%d ' %(batch_size) + ', Date:' + Time_Now + '\\n'\n",
    "    \n",
    "    return results\n",
    "\n",
    "clf = [NN_clf1,NN_clf2,NN_clf3,NN_clf4,NN_clf5, dtc, rfc, knn, xgb, svm]\n",
    "clf_name = ['NN_clf1','NN_clf2','NN_clf3','NN_clf4', 'NN_clf5', 'dtc', 'rfc', 'knn', 'xgb', 'svm']\n",
    "\n",
    "outputs_after=[parallel_ensemble.remote(clf[i], clf_name[i], new_X,y) for i in range (len(clf_name))]\n",
    "\n",
    "    \n",
    "#collect the results of classification after get new features from the bae classifier.\n",
    "path2=path + \"Res_Singl_Parallel_ML_DL_after.txt\" # the name of the file\n",
    "results_after='Dataset:' + dataset + '=============================================\\n'\n",
    "\n",
    "for i in range(len(clf_name)):\n",
    "    results_after+=ray.get(outputs_after[i])\n",
    "    \n",
    "all_time_after=time.time()-t1\n",
    "\n",
    "results_after+='Done...in time:' + str(round(all_time_after)) + '\\n'\n",
    "write_results(results_after, path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd84a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 13:54:17.219093: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-03-15 13:54:17.219138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (alandoli-Lenovo-Z50-70): /proc/driver/nvidia/version does not exist\n",
      "2023-03-15 13:54:17.219763: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step.118)\u001b[0m \n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1ceb1eaf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1cea6ac040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Done...in time:  77.91781377792358\n"
     ]
    }
   ],
   "source": [
    "#Ensemble stacked results\n",
    "t2=time.time()\n",
    "#kfold = KFold(n_splits=10, shuffle=True)\n",
    "clf = StackingClassifier(estimators=intermediate, final_estimator=LogisticRegression()) #MLPClassifier()\n",
    "\n",
    "clf.fit(new_x_train , y_train)\n",
    "#score = cross_val_score(stack_model,new_X,y,cv = 10,scoring = 'accuracy')\n",
    "#score\n",
    "y_predict=clf.predict(new_x_test)\n",
    "acc=accuracy_score(y_predict,y_test)\n",
    "prc=precision_score(y_predict,y_test, average='weighted')\n",
    "rec=recall_score(y_predict,y_test, average='weighted')\n",
    "f1=f1_score(y_predict,y_test, average='weighted')\n",
    "\n",
    "Ense_results ='Acc: %.2f' % (acc*100) + ', Pre: %.2f' % (prc*100)\n",
    "Ense_results += ', Rec: %.2f' % (rec*100) + ', F1: %.2f' % (f1*100) + ', PC: ' + PC\n",
    "Ense_results += ', Num Processors: ' + str(num_P) +  ', Eb:%d ' %(num_epochs) + ', Bs:%d ' %(batch_size) + 'Dataset: ' + dataset  + ', Date:' + Time_Now + '\\n'\n",
    "  \n",
    "Ense_results+='Done...in time:' + str(round(time.time()-t2)) + '\\n'\n",
    "\n",
    "path2= path + \"Res_Parallel_Ensemble_ML_DL.txt\" # the name of the file\n",
    "write_results(Ense_results, path2)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Done...in time: \", time.time()-t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "551b215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Stacking model score 0.9038461538461539\n"
     ]
    }
   ],
   "source": [
    "print(\"Stacking model score\", clf.score(new_x_test , y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a037c4b-a57a-4211-b549-26c4ed59acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf0c0a-2827-4c21-a181-d63b2b1fa369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a9f76c-5c30-4901-8a9d-6ac2caad9046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0268e6e-13f9-4b66-9d19-1ba0f827e77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
